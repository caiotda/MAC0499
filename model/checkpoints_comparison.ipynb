{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be2ff45e-7bfc-49c0-9e5d-ecdb5e6c698c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from model import NERClassifier\n",
    "from preprocess_dataset import NERDataset \n",
    "from trainner import Trainner\n",
    "from transformers import BertTokenizerFast\n",
    "from preprocess_dataset import remove_empty_entries\n",
    "\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278b8d62-1209-44cf-af79-0245484a09d5",
   "metadata": {},
   "source": [
    "## Checkpoints to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "055f8e3f-1de3-476c-8b0b-8facfbccbe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_base_cased    = 'neuralmind/bert-base-portuguese-cased'\n",
    "pt_large_cased   = 'neuralmind/bert-large-portuguese-cased'\n",
    "en_base_uncased = 'bert-base-uncased'\n",
    "en_large_uncased = 'bert-large-uncased'\n",
    "en_base_cased = 'bert-base-cased'\n",
    "en_large_cased = 'bert-large-cased'\n",
    "\n",
    "pt = [pt_base_cased, pt_large_cased]\n",
    "en = [en_base_cased, en_large_cased, en_base_uncased, en_large_uncased]\n",
    "cased = [pt_base_cased, en_base_cased, pt_large_cased, en_large_cased]\n",
    "uncased = [en_base_uncased, en_large_uncased] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "251fd139-3807-4ea0-b50b-5669bb794bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [pt, en]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04d2acaf-2d08-485a-b7d9-3d2d29eb7bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_models = [check for checkpoints in models for check in checkpoints]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e1eaec4-a9a0-4fd2-8521-b0a3bb93c27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "portuguese_flat = list(filter(lambda x: x.find('/') != -1, flat_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2ebc270-435d-4976-b771-7ead4f28ca05",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_flat = list(filter(lambda x: x.find('/') == -1, flat_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c938b54f-6eab-409a-95f2-76d4b66b800e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bert-base-cased',\n",
       " 'bert-large-cased',\n",
       " 'bert-base-uncased',\n",
       " 'bert-large-uncased']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f906c54b-df78-4a3b-9524-18612729bcc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neuralmind/bert-base-portuguese-cased',\n",
       " 'neuralmind/bert-large-portuguese-cased']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portuguese_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71a9bd00-2351-42bf-b513-2f205a5ef25c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neuralmind/bert-base-portuguese-cased',\n",
       " 'neuralmind/bert-large-portuguese-cased',\n",
       " 'bert-base-cased',\n",
       " 'bert-large-cased',\n",
       " 'bert-base-uncased',\n",
       " 'bert-large-uncased']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eabcb836-7e5d-4dd0-9b76-899395fa626c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flat_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edd8865-974c-42a1-8f4c-36e38f61fd70",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7aed8e0c-d15f-4e5d-b19b-848a24b39997",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset lener_br (/home/caiotulio/.cache/huggingface/datasets/lener_br/lener_br/1.0.0/4a8c97e6813b5c2d85a50faf0a3e6c24ea82f4a9044e6e9e8b24997d27399382)\n",
      "Loading cached processed dataset at /home/caiotulio/.cache/huggingface/datasets/lener_br/lener_br/1.0.0/4a8c97e6813b5c2d85a50faf0a3e6c24ea82f4a9044e6e9e8b24997d27399382/cache-5e59bc59f25f3d7f.arrow\n",
      "Loading cached processed dataset at /home/caiotulio/.cache/huggingface/datasets/lener_br/lener_br/1.0.0/4a8c97e6813b5c2d85a50faf0a3e6c24ea82f4a9044e6e9e8b24997d27399382/cache-8d0457760cd67ee6.arrow\n",
      "Loading cached processed dataset at /home/caiotulio/.cache/huggingface/datasets/lener_br/lener_br/1.0.0/4a8c97e6813b5c2d85a50faf0a3e6c24ea82f4a9044e6e9e8b24997d27399382/cache-74e841c1c151996a.arrow\n"
     ]
    }
   ],
   "source": [
    "data = \"lener_br\"\n",
    "dataset = load_dataset(data)\n",
    "dataset = remove_empty_entries(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a32f69-513f-4a31-9276-c97095c2bb39",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68817378-4e18-4cd3-82fd-e182148bbb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "LEARNING_RATE=3e-4\n",
    "n_labels = 13\n",
    "BATCH_SIZE=8\n",
    "shuffle=True\n",
    "NUM_EPOCHS=1\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d81e7a-32ad-4b1f-a3cc-5bb8d688050d",
   "metadata": {},
   "source": [
    "## Training different checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4d2477b-d699-40b3-887e-414f0d1e15aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from evaluator import Evaluator\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6b40c4a-4fa5-4948-90b8-17604287fb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(checkpoints):\n",
    "\n",
    "    data = {\"f1_t\":[], \"f1_e\":[], \"loss_t\": [], \"loss_e\": []}\n",
    "\n",
    "    for idx, checkpoint in enumerate(checkpoints):\n",
    "        print(f\"Progresso: {idx+1}/{len(checkpoints)}\")\n",
    "        print(f\"------Iniciando treino para o checkpoint {checkpoint}---------\")\n",
    "\n",
    "        tokenizer = BertTokenizerFast.from_pretrained(checkpoint)\n",
    "        print(\"Tokenizer carregado!\")\n",
    "        pytorch_dataset_train = NERDataset(data=dataset['train'], max_len=MAX_LEN, tokenizer=tokenizer)\n",
    "        loader = DataLoader(pytorch_dataset_train, batch_size=BATCH_SIZE, shuffle=shuffle)\n",
    "        print(\"Dataloader carregado!\")\n",
    "\n",
    "        model = NERClassifier(n_labels=n_labels, checkpoint=checkpoint)\n",
    "        optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, correct_bias=False)\n",
    "        evaluator = Evaluator(loader, model, device)\n",
    "        tr = Trainner(device,\\\n",
    "                      loader,\\\n",
    "                      model,\\\n",
    "                      optimizer,\\\n",
    "                      max_len=MAX_LEN,\\\n",
    "                      num_examples=len(pytorch_dataset_train),\\\n",
    "                      num_epochs=NUM_EPOCHS,\\\n",
    "                      evaluator=evaluator)\n",
    "        print(\"Trainner carregado!\")\n",
    "        loss_t, loss_e, f1_e, f1_t = tr.train()\n",
    "        print(f\"Treino finalizado para o checkpoint {checkpoint}\\n\" + \\\n",
    "              f\"loss_t:{loss_t}, loss_e:{loss_e}, f1_e:{f1_e}, f1_t:{f1_t}\")\n",
    "        data[\"f1_t\"].append(f1_t[0]) # We return the f1 score for all epochs. Since we're using \n",
    "        data[\"f1_e\"].append(f1_e[0]) # num_epochs=1, we'll just take the first item.\n",
    "        data[\"loss_t\"].append(loss_t[0])\n",
    "        data[\"loss_e\"].append(loss_e[0])\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87c007c5-7bc2-4f02-9c2d-4811b9daa93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progresso: 1/2\n",
      "------Iniciando treino para o checkpoint bert-base-uncased---------\n",
      "Tokenizer carregado!\n",
      "Dataloader carregado!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainner carregado!\n",
      "Começando treino! Essa função retorna a media de f1 e loss em cada epoch de treino e avaliação\n",
      "----------Começando treino da epoch nº 1\n",
      "Treinando em cuda\n",
      "Iteração 0 -------- Loss: 2.344785690307617 f1 nas ultimas 100 iterações: 0.004580497266795979 ------ Progresso: 0.00%.\n",
      "Iteração 100 -------- Loss: 0.8272997140884399 f1 nas ultimas 100 iterações: 0.7546770773516339 ------ Progresso: 10.21%.\n",
      "Iteração 200 -------- Loss: 1.482980489730835 f1 nas ultimas 100 iterações: 0.8146044723696698 ------ Progresso: 20.43%.\n",
      "Iteração 300 -------- Loss: 0.2990460991859436 f1 nas ultimas 100 iterações: 0.815000685096214 ------ Progresso: 30.64%.\n",
      "Iteração 400 -------- Loss: 0.27978137135505676 f1 nas ultimas 100 iterações: 0.8009900016420815 ------ Progresso: 40.86%.\n",
      "Iteração 500 -------- Loss: 0.9474799633026123 f1 nas ultimas 100 iterações: 0.8213372307469158 ------ Progresso: 51.07%.\n",
      "Iteração 600 -------- Loss: 0.6051630973815918 f1 nas ultimas 100 iterações: 0.815022591184831 ------ Progresso: 61.29%.\n",
      "Iteração 700 -------- Loss: 0.3958389461040497 f1 nas ultimas 100 iterações: 0.8091693287867934 ------ Progresso: 71.50%.\n",
      "Iteração 800 -------- Loss: 0.33031129837036133 f1 nas ultimas 100 iterações: 0.8238324755068098 ------ Progresso: 81.72%.\n",
      "Iteração 900 -------- Loss: 0.589216947555542 f1 nas ultimas 100 iterações: 0.8103045590940964 ------ Progresso: 91.93%.\n",
      "----------Fim do treino. Iniciando avaliação!\n",
      "Iteração 100 -------- Loss: 0.4871927797794342 f1 nas ultimas 100 iterações: 0.826748189904433 ------ Progresso: 10.21%.\n",
      "Iteração 200 -------- Loss: 0.6553060412406921 f1 nas ultimas 100 iterações: 0.818950248021296 ------ Progresso: 20.43%.\n",
      "Iteração 300 -------- Loss: 0.617811918258667 f1 nas ultimas 100 iterações: 0.8050494799099546 ------ Progresso: 30.64%.\n",
      "Iteração 400 -------- Loss: 1.30217707157135 f1 nas ultimas 100 iterações: 0.8122111898503859 ------ Progresso: 40.86%.\n",
      "Iteração 500 -------- Loss: 0.9637118577957153 f1 nas ultimas 100 iterações: 0.7952292027966357 ------ Progresso: 51.07%.\n",
      "Iteração 600 -------- Loss: 0.613058865070343 f1 nas ultimas 100 iterações: 0.8151853919188637 ------ Progresso: 61.29%.\n",
      "Iteração 700 -------- Loss: 0.5522124171257019 f1 nas ultimas 100 iterações: 0.8349879225550819 ------ Progresso: 71.50%.\n",
      "Iteração 800 -------- Loss: 0.7747641801834106 f1 nas ultimas 100 iterações: 0.8167858507005457 ------ Progresso: 81.72%.\n",
      "Iteração 900 -------- Loss: 0.6178740859031677 f1 nas ultimas 100 iterações: 0.7945796835731548 ------ Progresso: 91.93%.\n",
      "-------Fim da epoch nº 1\n",
      "Dados de treino: Loss media da epoch: 0.6993756038693291; f1 medio da epoch: 0.807418046747966\n",
      "Dados de avaliação: Loss media da epoch: 0.6620423011900334; f1 medio da epoch: 0.8127241101136541\n",
      "FIM DO TREINO! f1 media de treino ao fim de 1 epochs: 0.807418046747966\n",
      "Treino finalizado para o checkpoint bert-base-uncased\n",
      "loss_t:[0.6993756038693291], loss_e:[0.6620423011900334], f1_e:[0.8127241101136541], f1_t:[0.807418046747966]\n",
      "Progresso: 2/2\n",
      "------Iniciando treino para o checkpoint bert-large-uncased---------\n",
      "Tokenizer carregado!\n",
      "Dataloader carregado!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainner carregado!\n",
      "Começando treino! Essa função retorna a media de f1 e loss em cada epoch de treino e avaliação\n",
      "----------Começando treino da epoch nº 1\n",
      "Treinando em cuda\n",
      "Iteração 0 -------- Loss: 3.0868489742279053 f1 nas ultimas 100 iterações: 9.977827050997783e-05 ------ Progresso: 0.00%.\n",
      "Iteração 100 -------- Loss: 0.6433040499687195 f1 nas ultimas 100 iterações: 0.7753721256091479 ------ Progresso: 10.21%.\n",
      "Iteração 200 -------- Loss: 0.4900451898574829 f1 nas ultimas 100 iterações: 0.7995239944619591 ------ Progresso: 20.43%.\n",
      "Iteração 300 -------- Loss: 0.46434643864631653 f1 nas ultimas 100 iterações: 0.829660489728704 ------ Progresso: 30.64%.\n",
      "Iteração 400 -------- Loss: 0.6035807132720947 f1 nas ultimas 100 iterações: 0.8028153807876661 ------ Progresso: 40.86%.\n",
      "Iteração 500 -------- Loss: 0.22309009730815887 f1 nas ultimas 100 iterações: 0.8141738999863479 ------ Progresso: 51.07%.\n",
      "Iteração 600 -------- Loss: 0.44416260719299316 f1 nas ultimas 100 iterações: 0.8084743096221361 ------ Progresso: 61.29%.\n",
      "Iteração 700 -------- Loss: 1.0911970138549805 f1 nas ultimas 100 iterações: 0.8179277835146397 ------ Progresso: 71.50%.\n",
      "Iteração 800 -------- Loss: 0.4666636884212494 f1 nas ultimas 100 iterações: 0.8004246008945277 ------ Progresso: 81.72%.\n",
      "Iteração 900 -------- Loss: 0.2386828362941742 f1 nas ultimas 100 iterações: 0.816330776122491 ------ Progresso: 91.93%.\n",
      "----------Fim do treino. Iniciando avaliação!\n",
      "Iteração 100 -------- Loss: 0.5585426092147827 f1 nas ultimas 100 iterações: 0.8200177201584629 ------ Progresso: 10.21%.\n",
      "Iteração 200 -------- Loss: 0.49970534443855286 f1 nas ultimas 100 iterações: 0.8185484583848093 ------ Progresso: 20.43%.\n",
      "Iteração 300 -------- Loss: 0.5090427994728088 f1 nas ultimas 100 iterações: 0.8332280376121818 ------ Progresso: 30.64%.\n",
      "Iteração 400 -------- Loss: 1.0306737422943115 f1 nas ultimas 100 iterações: 0.7992733787376847 ------ Progresso: 40.86%.\n",
      "Iteração 500 -------- Loss: 0.5487386584281921 f1 nas ultimas 100 iterações: 0.8165414542911585 ------ Progresso: 51.07%.\n",
      "Iteração 600 -------- Loss: 0.4888770878314972 f1 nas ultimas 100 iterações: 0.8132634201313216 ------ Progresso: 61.29%.\n",
      "Iteração 700 -------- Loss: 0.6165035367012024 f1 nas ultimas 100 iterações: 0.81973168331457 ------ Progresso: 71.50%.\n",
      "Iteração 800 -------- Loss: 0.9082037806510925 f1 nas ultimas 100 iterações: 0.8057881105183655 ------ Progresso: 81.72%.\n",
      "Iteração 900 -------- Loss: 0.5993722081184387 f1 nas ultimas 100 iterações: 0.7971145902241308 ------ Progresso: 91.93%.\n",
      "-------Fim da epoch nº 1\n",
      "Dados de treino: Loss media da epoch: 0.7080935852200676; f1 medio da epoch: 0.8070428290537472\n",
      "Dados de avaliação: Loss media da epoch: 0.6643940511257582; f1 medio da epoch: 0.8125583684423137\n",
      "FIM DO TREINO! f1 media de treino ao fim de 1 epochs: 0.8070428290537472\n",
      "Treino finalizado para o checkpoint bert-large-uncased\n",
      "loss_t:[0.7080935852200676], loss_e:[0.6643940511257582], f1_e:[0.8125583684423137], f1_t:[0.8070428290537472]\n",
      "CPU times: user 16min 27s, sys: 2min 27s, total: 18min 54s\n",
      "Wall time: 19min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_en_uncased = compare(en_flat[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c48e32c8-29a9-4232-b600-5d849dea4507",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en_uncased = pd.DataFrame(df_en_uncased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0138ba76-d83f-40e7-98f7-be30c1fd3b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en_uncased['checkpoint'] = en_flat[2:]\n",
    "df_en_uncased = df_en_uncased.set_index('checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8b235db-a92c-45b1-a3a1-69b06d972839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_t</th>\n",
       "      <th>f1_e</th>\n",
       "      <th>loss_t</th>\n",
       "      <th>loss_e</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>checkpoint</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bert-base-uncased</th>\n",
       "      <td>0.807418</td>\n",
       "      <td>0.812724</td>\n",
       "      <td>0.699376</td>\n",
       "      <td>0.662042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-large-uncased</th>\n",
       "      <td>0.807043</td>\n",
       "      <td>0.812558</td>\n",
       "      <td>0.708094</td>\n",
       "      <td>0.664394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        f1_t      f1_e    loss_t    loss_e\n",
       "checkpoint                                                \n",
       "bert-base-uncased   0.807418  0.812724  0.699376  0.662042\n",
       "bert-large-uncased  0.807043  0.812558  0.708094  0.664394"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_en_uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4b706cbd-758c-4748-8cdb-99c0c89f5ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en_uncased.to_csv('checkpoint_en_uncased.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "20f0684a-7870-4d58-a7f2-ebf3f9336f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pt = pd.read_csv('checkpoint_pt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9922e7b9-0264-4d36-b253-e866d23db52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en_cased = pd.read_csv('checkpoint_en_cased.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80250b4e-6f21-4de9-9b7b-2e204f38e7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([df_pt, df_en_cased, df_en_uncased])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a41cc093-6615-4812-8cd0-d4ff5be49b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checkpoint</th>\n",
       "      <th>f1_t</th>\n",
       "      <th>f1_e</th>\n",
       "      <th>loss_t</th>\n",
       "      <th>loss_e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neuralmind/bert-base-portuguese-cased</td>\n",
       "      <td>0.814131</td>\n",
       "      <td>0.815739</td>\n",
       "      <td>0.666314</td>\n",
       "      <td>0.661454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neuralmind/bert-large-portuguese-cased</td>\n",
       "      <td>0.812499</td>\n",
       "      <td>0.815978</td>\n",
       "      <td>0.691230</td>\n",
       "      <td>0.659751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>0.811261</td>\n",
       "      <td>0.813640</td>\n",
       "      <td>0.680731</td>\n",
       "      <td>0.668316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert-large-cased</td>\n",
       "      <td>0.811336</td>\n",
       "      <td>0.811681</td>\n",
       "      <td>0.691754</td>\n",
       "      <td>0.660262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-base-uncased</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.807418</td>\n",
       "      <td>0.812724</td>\n",
       "      <td>0.699376</td>\n",
       "      <td>0.662042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-large-uncased</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.807043</td>\n",
       "      <td>0.812558</td>\n",
       "      <td>0.708094</td>\n",
       "      <td>0.664394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                checkpoint      f1_t  \\\n",
       "0                    neuralmind/bert-base-portuguese-cased  0.814131   \n",
       "1                   neuralmind/bert-large-portuguese-cased  0.812499   \n",
       "0                                          bert-base-cased  0.811261   \n",
       "1                                         bert-large-cased  0.811336   \n",
       "bert-base-uncased                                      NaN  0.807418   \n",
       "bert-large-uncased                                     NaN  0.807043   \n",
       "\n",
       "                        f1_e    loss_t    loss_e  \n",
       "0                   0.815739  0.666314  0.661454  \n",
       "1                   0.815978  0.691230  0.659751  \n",
       "0                   0.813640  0.680731  0.668316  \n",
       "1                   0.811681  0.691754  0.660262  \n",
       "bert-base-uncased   0.812724  0.699376  0.662042  \n",
       "bert-large-uncased  0.812558  0.708094  0.664394  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "73d1bfc9-b436-4632-bc4c-8d43b7c2a0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checkpoint</th>\n",
       "      <th>f1_t</th>\n",
       "      <th>f1_e</th>\n",
       "      <th>loss_t</th>\n",
       "      <th>loss_e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neuralmind/bert-base-portuguese-cased</td>\n",
       "      <td>0.814131</td>\n",
       "      <td>0.815739</td>\n",
       "      <td>0.666314</td>\n",
       "      <td>0.661454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neuralmind/bert-large-portuguese-cased</td>\n",
       "      <td>0.812499</td>\n",
       "      <td>0.815978</td>\n",
       "      <td>0.691230</td>\n",
       "      <td>0.659751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>0.811261</td>\n",
       "      <td>0.813640</td>\n",
       "      <td>0.680731</td>\n",
       "      <td>0.668316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bert-large-cased</td>\n",
       "      <td>0.811336</td>\n",
       "      <td>0.811681</td>\n",
       "      <td>0.691754</td>\n",
       "      <td>0.660262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.807418</td>\n",
       "      <td>0.812724</td>\n",
       "      <td>0.699376</td>\n",
       "      <td>0.662042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.807043</td>\n",
       "      <td>0.812558</td>\n",
       "      <td>0.708094</td>\n",
       "      <td>0.664394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               checkpoint      f1_t      f1_e    loss_t  \\\n",
       "0   neuralmind/bert-base-portuguese-cased  0.814131  0.815739  0.666314   \n",
       "1  neuralmind/bert-large-portuguese-cased  0.812499  0.815978  0.691230   \n",
       "2                         bert-base-cased  0.811261  0.813640  0.680731   \n",
       "3                        bert-large-cased  0.811336  0.811681  0.691754   \n",
       "4                                     NaN  0.807418  0.812724  0.699376   \n",
       "5                                     NaN  0.807043  0.812558  0.708094   \n",
       "\n",
       "     loss_e  \n",
       "0  0.661454  \n",
       "1  0.659751  \n",
       "2  0.668316  \n",
       "3  0.660262  \n",
       "4  0.662042  \n",
       "5  0.664394  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ffaf5b38-39ba-4245-a0bd-011b22cae5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[\"checkpoint\"] = flat_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "50ffc832-9e37-4007-a236-c7ef8f5394be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final=df_final.set_index(\"checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ef60ff95-a799-4358-bdcb-c4c3efd28ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_t</th>\n",
       "      <th>f1_e</th>\n",
       "      <th>loss_t</th>\n",
       "      <th>loss_e</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>checkpoint</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neuralmind/bert-base-portuguese-cased</th>\n",
       "      <td>0.814131</td>\n",
       "      <td>0.815739</td>\n",
       "      <td>0.666314</td>\n",
       "      <td>0.661454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neuralmind/bert-large-portuguese-cased</th>\n",
       "      <td>0.812499</td>\n",
       "      <td>0.815978</td>\n",
       "      <td>0.691230</td>\n",
       "      <td>0.659751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-base-cased</th>\n",
       "      <td>0.811261</td>\n",
       "      <td>0.813640</td>\n",
       "      <td>0.680731</td>\n",
       "      <td>0.668316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-large-cased</th>\n",
       "      <td>0.811336</td>\n",
       "      <td>0.811681</td>\n",
       "      <td>0.691754</td>\n",
       "      <td>0.660262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-base-uncased</th>\n",
       "      <td>0.807418</td>\n",
       "      <td>0.812724</td>\n",
       "      <td>0.699376</td>\n",
       "      <td>0.662042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-large-uncased</th>\n",
       "      <td>0.807043</td>\n",
       "      <td>0.812558</td>\n",
       "      <td>0.708094</td>\n",
       "      <td>0.664394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            f1_t      f1_e    loss_t    loss_e\n",
       "checkpoint                                                                    \n",
       "neuralmind/bert-base-portuguese-cased   0.814131  0.815739  0.666314  0.661454\n",
       "neuralmind/bert-large-portuguese-cased  0.812499  0.815978  0.691230  0.659751\n",
       "bert-base-cased                         0.811261  0.813640  0.680731  0.668316\n",
       "bert-large-cased                        0.811336  0.811681  0.691754  0.660262\n",
       "bert-base-uncased                       0.807418  0.812724  0.699376  0.662042\n",
       "bert-large-uncased                      0.807043  0.812558  0.708094  0.664394"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cc606011-8636-4022-bc48-c92437b9bbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(\"all_checkpoints.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
